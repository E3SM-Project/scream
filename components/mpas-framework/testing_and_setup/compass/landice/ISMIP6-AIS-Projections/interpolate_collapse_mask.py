#!/usr/bin/env python
'''
Interpolate fields from an input file to a pre-existing MPAS-LI grid.

The input file can either be CISM format or MPASLI format.

For CISM input files, three interpolation methods are supported:
* a built-in bilinear interpolation method
* a built-in barycentric interpolation method (nearest neighbor is used for extrapolation regions)
* using weights generated by ESMF

For MPAS input files only barycentric interpolation is supported.
'''

from __future__ import absolute_import, division, print_function, \
    unicode_literals

import sys
import numpy as np
import netCDF4
from optparse import OptionParser
import math
from collections import OrderedDict
import scipy.spatial
import time
from datetime import datetime


print("== Gathering information.  (Invoke with --help for more details. All arguments are optional)\n")
parser = OptionParser()
parser.description = __doc__
parser.add_option("-s", "--source", dest="inputFile", help="name of source (input) file.  NOTE: 8km and higher resolution fields are very blocky and unrealistic looking.  It is better to use 16 or 32 km resolution where the fractional mask value is rounded to 0 or 1.  This results in a smoother, more realistic-looking maski.  16km resolution appears to be the best compromise between fidelity to the original (pixely) data and smoothness.", metavar="FILENAME")
parser.add_option("-d", "--destination", dest="mpasFile", help="name of destination file on which to interpolate fields.",  metavar="FILENAME")
parser.add_option("-i", "--initial", dest="icFile", help="initial condition file", metavar="FILENAME")
for option in parser.option_list:
    if option.default != ("NO", "DEFAULT"):
        option.help += (" " if option.help else "") + "[default: %default]"
options, args = parser.parse_args()

print("  Source file:  {}".format(options.inputFile))
print("  Destination MPASLI file to be modified:  {}".format(options.mpasFile))

print('') # make a space in stdout before further output


#----------------------------
#----------------------------
# Define needed functions
#----------------------------
#----------------------------

#----------------------------

def delaunay_interp_weights(xy, uv, d=2):
    '''
    xy = input x,y coords
    uv = output (MPSALI) x,y coords
    '''

    #print("scipy version=", scipy.version.full_version)
    if xy.shape[0] > 2**24-1:
       print("WARNING: The source file contains more than 2^24-1 (16,777,215) points due to a limitation in older versions of Qhull (see: https://mail.scipy.org/pipermail/scipy-user/2015-June/036598.html).  Delaunay creation may fail if Qhull being linked by scipy.spatial is older than v2015.0.1 2015/8/31.")

    tri = scipy.spatial.Delaunay(xy)
    print("    Delaunay triangulation complete.", flush=True)
    simplex = tri.find_simplex(uv)
    print("    find_simplex complete.", flush=True)
    vertices = np.take(tri.simplices, simplex, axis=0)
    print("    identified vertices.", flush=True)
    temp = np.take(tri.transform, simplex, axis=0)
    print("    np.take complete.", flush=True)
    delta = uv - temp[:, d]
    bary = np.einsum('njk,nk->nj', temp[:, :d, :], delta)
    print("    calculating bary complete.", flush=True)
    wts = np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))

    return vertices, wts

#----------------------------

def delaunay_interpolate(values):
    vtx = vtx1; wts = wts1

    outfield = np.einsum('nj,nj->n', np.take(values, vtx), wts)

    return outfield


#----------------------------
#----------------------------




print("==================")
print('Gathering coordinate information from input and output files.')


# Open the output file, get needed dimensions & variables
try:
    MPASfile = netCDF4.Dataset(options.mpasFile,'r+')
    MPASfile.set_auto_mask(False)

    # '2d' spatial fields on cell centers
    xCell = MPASfile.variables['xCell'][:]
    #print('xCell min/max:', xCell.min(), xCell.max()
    yCell = MPASfile.variables['yCell'][:]
    #print('yCell min/max:', yCell.min(), yCell.max()
    nCells = len(MPASfile.dimensions['nCells'])

except:
    sys.exit('Error: The output grid file specified is either missing or lacking needed dimensions/variables.')
print("==================\n")



# Open the input file, get needed dimensions
inputFile = netCDF4.Dataset(options.inputFile,'r')
inputFile.set_auto_mask(False)

# Figure out if this is CISM or MPAS
if 'x1' in inputFile.variables:
    filetype='cism'
else:
        sys.exit("ERROR: Unknown file type.  ")

if filetype=='cism':
    # Get CISM location variables if they exist
    try:
      x1 = inputFile.variables['x1'][:]
      dx1 = x1[1] - x1[0]
      #print('x1 min/max/dx:', x1.min(), x1.max(), dx1
      y1 = inputFile.variables['y1'][:]
      dy1 = y1[1] - y1[0]
      #print('y1 min/max/dx:', y1.min(), y1.max(), dy1

    except:
      print('  Input file is missing x1 and/or y1.  Might not be a problem.')

    # Check the overlap of the grids
    print('==================')
    print('Input File extents:')
    print('  x1 min, max:    {} {}'.format(x1.min(), x1.max()))
    print('  y1 min, max:    {} {}'.format(y1.min(), y1.max()))
    print('MPAS File extents:')
    print('  xCell min, max: {} {}'.format(xCell.min(), xCell.max()))
    print('  yCell min, max: {} {}'.format(yCell.min(), yCell.max()))
    print('==================')


#----------------------------
# Setup Delaunay/barycentric interpolation weights if needed
mpasXY = np.vstack((xCell[:], yCell[:])).transpose()

[Yi,Xi] = np.meshgrid(x1[:], y1[:])
cismXY1 = np.zeros([Xi.shape[0]*Xi.shape[1],2])
cismXY1[:,0] = Yi.flatten()
cismXY1[:,1] = Xi.flatten()

print('\nBuilding interpolation weights: CISM x1/y1 -> MPAS', flush=True)
start = time.clock()
vtx1, wts1 = delaunay_interp_weights(cismXY1, mpasXY)
end = time.clock(); print('done in {}'.format(end-start), flush=True)


# ------- get/create out field ---
if 'calvingMask' in MPASfile.variables:
    outMask = MPASfile.variables['calvingMask']
else:
    outMask = MPASfile.createVariable('calvingMask','i',('Time','nCells'))

StrLen=64
if 'xtime' in MPASfile.variables:
    xtime = MPASfile.variables['xtime']
else:
    if not 'StrLen' in MPASfile.dimensions:
       print("adding StrLen")
       MPASfile.createDimension('StrLen', StrLen)
    print("adding xtime")
    xtime = MPASfile.createVariable('xtime','c', ('Time', 'StrLen'))


# create initial extent mask
fic = netCDF4.Dataset(options.icFile,'r')
thk = fic.variables['thickness'][0,:]
bed = fic.variables['bedTopography'][0,:]
icMask = (thk==0.0) * (bed<0.0)  # locate places where there is no ice and is ocean.  Calving will be forced here.


#----------------------------
nt = len(inputFile.dimensions['time'])
inMask = inputFile.variables['mask']

startYear=1995
for t in range(nt):
    print('time={}'.format(t), flush=True)

    start = time.clock()
    interpMask = np.round(delaunay_interpolate(inMask[t,:,:]))
    outMask[t,:] = np.maximum(interpMask, icMask)
    end = time.clock(); print('  interpolation done in {}'.format(end-start))

    time_string = "{:04}-01-01_00:00:00".format(t+startYear)
    print(time_string)
    MPASfile.variables['xtime'][t,:] = list(time_string.ljust(StrLen))

    MPASfile.sync()  # update the file now in case we get an error later


# Update history attribute of netCDF file
thiscommand = datetime.now().strftime("%a %b %d %H:%M:%S %Y") + ": " + " ".join(sys.argv[:])
if hasattr(MPASfile, 'history'):
   newhist = '\n'.join([thiscommand, getattr(MPASfile, 'history')])
else:
   newhist = thiscommand
setattr(MPASfile, 'history', newhist )

inputFile.close()
MPASfile.close()

print('\nInterpolation completed.')
